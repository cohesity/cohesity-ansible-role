#!/usr/bin/python
# Copyright (c) 2022 Cohesity Inc
# Apache License Version 2.0

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import json
from collections import defaultdict
from ansible.module_utils.basic import AnsibleModule
from ansible.module_utils.urls import open_url, urllib_error

try:
    # => When unit testing, we need to look in the correct location however, when run via ansible,
    # => the expectation is that the modules will live under ansible.
    from ansible_collections.cohesity.cohesity_collection.plugins.module_utils.cohesity_auth import get__cohesity_auth__token
    from ansible_collections.cohesity.cohesity_collection.plugins.module_utils.cohesity_utilities import cohesity_common_argument_spec, raise__cohesity_exception__handler, REQUEST_TIMEOUT
    from ansible_collections.cohesity.cohesity_collection.plugins.module_utils.cohesity_hints import get__prot_source_id__by_endpoint, \
        get__prot_source_root_id__by_environment, get__prot_policy_id__by_name, \
        get__storage_domain_id__by_name, get__protection_jobs__by_environment, \
        get__protection_run__all__by_id, get_cohesity_client
except Exception as e:
    pass # pass

ANSIBLE_METADATA = {
    'metadata_version': '1.0',
    'supported_by': 'community',
    'status': ['preview']
}


DOCUMENTATION = '''
module: cohesity_job
short_description: Management of Cohesity Protection Jobs
description:
    - Ansible Module used to register, remove, start, and stop the Cohesity Protection Job on a Cohesity Cluster.
    - When executed in a playbook, the Cohesity Protection Job will be validated and the appropriate state action
    - will be applied.
version_added: '2.6.5'
author:
  - Jeremy Goodrum (github.com/exospheredata)
  - Cohesity, Inc

options:
  state:
    description:
      - Determines the state of the Protection Job
    choices:
      - present
      - absent
      - started
      - stopped
    default: present
  name:
    description:
      - Name to assign to the Protection Job
    required: yes
  description:
    description:
      - Optional Description to assign to the Protection Job
  environment:
    description:
      - Specifies the environment type (such as VMware or SQL) of the Protection Source this Job
      - is protecting. Supported environment types include 'PhysicalFiles', 'VMware'
    choices:
      - VMware
      - PhysicalFiles
      - GenericNas
    required: yes
  protection_sources:
    description:
      - A list of dictionaries with endpoints and paths to backup. Required when I(state=present).
    usage:
      protection_sources:
        - endpoint: ""
          paths: (valid only for physical sources and file based protection jobs)
            - includeFilePath: (String, default "/" for linux machines, required field for windows machines)
              excludeFilePaths: (List, defaults to empty list [], optional field)
                 - String
                 - String
              skipNestedVolumes: True (Boolean, defaults to True)
  protection_policy:
    description:
      - Valid policy name or ID for andexisting Protection Policy to be assigned to the job.
      - Required when I(state=present).
  storage_domain:
    description:
      - Existing Storage Domain to which the Protection Job will be associated. Required when I(state=present).
  time_zone:
    description:
      - Specifies the timezone to use when calculating time for this Protection Job such as the Job start time.
    default: 'America/Los_Angeles'
  start_time:
    description:
      - Specifies the registered start time for the Protection Job.  Format must be 24hr time in either HHMM or HH:MM style.
      - If not configured then the Cluster will automatically select a time.
  delete_backups:
    description:
      - Specifies if Snapshots generated by the Protection Job should also be deleted when the Job is deleted.
      - Optional and only valid when I(state=absent)
    type: bool
    default: no
  delete_sources:
    description:
      - Specifies job is already available, if source available in Protection Job needs to be removed.
      - Optional and only valid when (environment=Physical, PhysicalFiles, GenericNas)
    type: bool
    default: True
  append_to_existing:
    description:
      - Specifies when job is already available and new list of virtual machines needs to be added to existing list.
      - If not specified new list of vms will replace the existing vms available in the Protection job.
      - Optional and only valid when (environment=VMware)
    type: bool
    default: False
  ondemand_run_type:
    description:
      - Specifies the type of OnDemand Backup.
    choices:
      - Regular
      - Full
      - Log
      - System
    default: 'Regular'
  cancel_active:
    description:
      - Specifies if Current Running Backup Job should be canceled.  If False, active jobs will not be stopped
      - and a failure will be raised.
      - Optional and only valid when I(state=stopped)
    type: bool
    default: no

extends_documentation_fragment:
    - cohesity
requirements: []
'''

EXAMPLES = '''
# Create a new Physical Server Protection Job
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: present
    name: myhost
    environment: PhysicalFiles
    protection_sources:
      - myhost.domain.lab
    protection_policy: Bronze
    storage_domain: Default

# Create a new VMware Server Protection Job
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: present
    name: myvcenter
    environment: VMware
    protection_sources:
      - myvcenter.domain.lab
    protection_policy: Gold
    storage_domain: Default

# Remove an existing VMware Server Protection Job
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: absent
    name: myvcenter
    environment: VMware

# Remove an existing VMware Server Protection Job and remove all Backups
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: absent
    name: myvcenter
    environment: VMware
    delete_backups: True

# Start an existing VMware Server Protection Job
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: started
    name: myvcenter
    environment: VMware

# Stop an actively running VMware Server Protection Job
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: stopped
    name: myvcenter
    environment: VMware
'''

RETURN = '''
Returns the registered Protection Job ID
'''


class ParameterViolation(Exception):
    pass


class ProtectionException(Exception):
    pass


def check__mandatory__params(module):
    # => This method will perform validations of optionally mandatory parameters
    # => required for specific states and environments.
    success = True
    missing_params = list()
    environment = module.params.get('environment')

    if module.params.get('state') == 'present':
        action = 'creation'

        if not module.params.get('protection_sources'):
            success = False
            missing_params.append('protection_sources')
        if not module.params.get('protection_policy'):
            success = False
            missing_params.append('protection_policy')
        if not module.params.get('storage_domain'):
            success = False
            missing_params.append('storage_domain')

    else:
        action = 'remove'

    if not success:
        module.fail_json(
            msg="The following variables are mandatory for this action (" +
            action +
            ") when working with environment type (" +
            environment +
            ")",
            missing=missing_params)


def check__protection_job__exists(module, self):
    try:
        job_list = get__protection_jobs__by_environment(module, self)

        for job in job_list:
            if job['name'] == self['name']:
                return job['id'], job

        return False, ""
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def wait__for_job_state__transition(module, self, job_runs, state='start'):
    if not job_runs:
        job_runs = []
    if state != 'start':
        state = 'stop'
    import time
    loop_cnt = 0
    while loop_cnt <= 20:
        payload = self.copy()
        # => If the backup finishes before we check, we need to look
        # => at previous backups to see if the last job is successful.
        payload['active_only'] = False
        if state == 'stop':
            # => If we are checking to see if the job is stopped, then
            # => Simply filtering out the active jobs will suffice.
            payload['active_only'] = True
        payload['is_deleted'] = False
        for job_run in job_runs:
            currently_active = get__protection_run__all__by_id(
                module, payload)
            if state == 'start':
                if currently_active:
                    status = currently_active[0][
                        'backupRun']['status'].lstrip('k')
                    valid_states = ['Accepted', 'Success', 'Running']
                    for check_state in valid_states:
                        if status == check_state:
                            try:
                                job_runs.pop(job_run)
                            except Exception as e:
                                if len(job_runs) == 1:
                                    job_runs = []
            else:
                if not currently_active:
                    try:
                        job_runs.pop(job_run)
                    except Exception as e:
                        if len(job_runs) == 1:
                            job_runs = []
        if not job_runs:
            break
        else:
            time.sleep(5)
            loop_cnt += 1

    if loop_cnt == 21:
        module.fail_json(
            msg="Failed to successfully " +
            state +
            " the Cohesity Protection Job",
            changed=False,
            id=self['id'],
            loop_cnt=loop_cnt)


def convert_windows_file_paths(path):
    if ':' in path:
        path_structure = path.split(":")
        path = "/" + path_structure[0] + path_structure[1]
        for char in ("\\\\", "\\"):
            path = path.replace(char, "/")
    return path


def create_paths_parameter(module, update_source_ids):
    sources_with_paths = []
    for source in module.params.get('protection_sources'):
        if (source['endpoint'] is not None) and source['endpoint'] in update_source_ids:
            source_paths = {}
            source_paths['sourceId'] = source['endpoint']
            source_paths['physicalSpecialParameters'] = {}
            if 'paths' in source:
                source_paths['physicalSpecialParameters']['filepaths'] = []
                for path in source['paths']:
                    t = {}
                    t.setdefault('backupFilePath', '/')
                    t.setdefault('excludedFilePaths', [])
                    t.setdefault('skipNestedVolumes', True)
                    if 'includeFilePath' in path:
                        t['backupFilePath'] = convert_windows_file_paths(path['includeFilePath'])
                    if 'excludeFilePaths' in path:
                        files = []
                        for file in path['excludeFilePaths']:
                            files.append(convert_windows_file_paths(file))
                        t['excludedFilePaths'] = files
                    if 'skipNestedVolumes' in path:
                        t['skipNestedVolumes'] = path['skipNestedVolumes']

                    source_paths['physicalSpecialParameters']['filepaths'].append(t)
            else:
                source_paths['physicalSpecialParameters'] = {'filePaths': [
                                                      {'backupFilePath': "/", 'skipNestedVolumes': True}]}
            sources_with_paths.append(source_paths)
    return sources_with_paths


def parse_vmware_protection_sources_json(response, vm_names):
    ids = []
    nodes = []
    for node in response:
        if 'nodes' in node:
            nodes.append(node['nodes'])
        if ('protectionSource' in node) and (node['protectionSource']['name'] in vm_names):
            ids.append(node['protectionSource']['id'])

    while len(nodes) != 0:
        objects = nodes.pop()
        for node in objects:
            if 'nodes' in node:
                nodes.append(node['nodes'])
            if ('protectionSource' in node) and (node['protectionSource']['name'] in vm_names):
                ids.append(node['protectionSource']['id'])
    return list(set(ids))


def _get_tag_ids(module, tags, parentSourceId):
    """
    Function to fetch VMware tag ids for list of tag names.
    """ 
    try:
        client = get_cohesity_client(module)
        if not client:
            module.fail_json(
                msg="Error while creating cohesity client, err msg '%s'" % client,
                changed=False)
        result = client.protection_sources.list_protection_sources(
            id=parentSourceId)
        if not result or not result[0].nodes:
            module.fail_json(
                msg="Failed to fetch tags for source with id " + str(
                    parentSourceId), changed=False)
        nodes = result[0].nodes
        return parse_vmware_protection_sources_json(nodes, tags)
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def get_vmware_ids(module, job_meta_data, job_details, vm_names):
    server = module.params.get('cluster')
    validate_certs = module.params.get('validate_certs')
    token = job_details['token']
    try:
        uri = "https://" + server + "/irisservices/api/v1/public/protectionSources?id=" + \
            str(job_meta_data['parentSourceId'])
        headers = {"Accept": "application/json",
                   "Authorization": "Bearer " + token,
                   "user-agent": "cohesity-ansible/v0.0.1"}
        response = open_url(
            url=uri,
            method='GET',
            headers=headers,
            validate_certs=validate_certs, timeout=REQUEST_TIMEOUT)

        if not response.getcode() == 200:
            raise ProtectionException(
                msg="Failed to get VMware protection source details")
        response = json.loads(response.read())
        ids = parse_vmware_protection_sources_json(response, vm_names)
        return ids
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def get_vmware_vm_ids(module, job_meta_data, job_details, vm_names):
    server = module.params.get('cluster')
    validate_certs = module.params.get('validate_certs')
    token = job_details['token']
    try:
        uri = "https://" + server + \
              "/irisservices/api/v1/public/protectionSources/virtualMachines?vCenterId=" + str(job_meta_data['parentSourceId'])
        headers = {"Accept": "application/json",
                   "Authorization": "Bearer " + token,
                   "user-agent": "cohesity-ansible/v0.0.1"}
        response = open_url(
            url=uri,
            method='GET',
            headers=headers,
            validate_certs=validate_certs, timeout=REQUEST_TIMEOUT)

        if not response.getcode() == 200:
            raise ProtectionException(
                msg="Failed to get VMware protection source details")
        response = json.loads(response.read())
        vm_ids = []
        vm_names_lowercase = [v.lower() for v in vm_names]
        for vm in response:
            if vm['name'].lower() in vm_names_lowercase:
                vm_ids.append(vm['id'])
        return vm_ids

    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def get_view_storage_domain_id(module, self):
    '''
    function to get view's storage domain id.
    :param module:
    :param self:
    :return:
    '''
    server = module.params.get('cluster')
    validate_certs = module.params.get('validate_certs')
    token = self['token']
    view_name = module.params.get('view_name')
    try:
        uri = "https://" + server + "/irisservices/api/v1/public/views/" + view_name
        headers = {"Accept": "application/json",
                   "Authorization": "Bearer " + token,
                   "user-agent": "cohesity-ansible/v0.0.1"}
        response = open_url(url=uri, method="GET", headers=headers,
                            validate_certs=validate_certs, timeout=REQUEST_TIMEOUT)
        response = json.loads(response.read())
        return response['viewBoxId']
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)

def update_indexing(module, payload):
    """
    """
    payload['indexingPolicy'] = {
        "disableIndexing": module.params.get('disable_indexing'),
        "allowPrefixes": ["/"],
        "denyPrefixes": [
            "/$Recycle.Bin",
            "/Windows",
            "/Program Files",
            "/Program Files (x86)",
            "/ProgramData",
            "/System Volume Information",
            "/Users/*/AppData",
            "/Recovery",
            "/var",
            "/usr",
            "/sys",
            "/proc",
            "/lib",
            "/grub",
            "/grub2",
            "/opt",
            "/splunk",
        ]
    }
    if module.params.get('indexing').get('allowed_prefix', None):
        payload['indexingPolicy']['allowPrefixes'] = module.params.get(
            'indexing')['allowed_prefix']
    if module.params.get('indexing').get('denied_prefix', None):
        payload['indexingPolicy']['denyPrefixes'] = module.params.get(
            'indexing')['denied_prefix']
    return payload

def register_job(module, self):
    server = module.params.get('cluster')
    validate_certs = module.params.get('validate_certs')
    token = self['token']
    try:
        uri = "https://" + server + "/irisservices/api/v1/public/protectionJobs"
        headers = {"Accept": "application/json",
                   "Authorization": "Bearer " + token,
                   "user-agent": "cohesity-ansible/v0.0.1"}
        payload = self.copy()

        # => Remove the Authorization Token from the Payload
        payload.pop('token', None)

        payload['environment'] = "k" + self['environment']
        payload['timezone'] = self['timezone']
        update_indexing(module, payload)
        if payload['environment'] == "kPhysicalFiles":
            payload['sourceSpecialParameters'] = create_paths_parameter(module, payload['sourceIds'])
        elif payload['environment'] == "kVMware":
            parent_source_id = {"parentSourceId": self['parentSourceId']}
            if len(module.params.get('include_tags')) != 0:
                tag_list = list()
                for tags in module.params.get('include_tags'):
                    tag_ids = _get_tag_ids(module, tags, self['parentSourceId'])
                    tag_list.append(tag_ids)
                payload['vmTagIds'] = tag_list
            if len(module.params.get('include')) != 0:
                vms = module.params.get('include')
                payload['sourceIds'] = get_vmware_ids(module, parent_source_id, self, vms)
            if len(module.params.get('exclude')) != 0:
                vms = module.params.get('exclude')
                payload['excludeSourceIds'] = get_vmware_ids(module, parent_source_id, self, vms)
        data = json.dumps(payload)
        response = open_url(url=uri, data=data, headers=headers,
                            validate_certs=validate_certs, timeout=REQUEST_TIMEOUT)

        response = json.loads(response.read())

        # => This dictionary will allow us to return a standardized output
        # => for all Protection Job.
        output = dict(
            id=response['id'],
            name=response['name'],
            environment=response['environment'].lstrip('k'),
            priority=response['priority'].lstrip('k'),
            start_time=response['startTime']
        )

        return output
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def start_job(module, self):
    server = module.params.get('cluster')
    validate_certs = module.params.get('validate_certs')
    token = self['token']

    payload = self.copy()
    payload['active_only'] = True
    payload['is_deleted'] = False
    currently_active = get__protection_run__all__by_id(module, payload)
    if currently_active:
        results = dict(
            changed=False,
            msg="The Protection Job for this host is currently running",
            name=module.params.get('name')
        )
        module.exit_json(**results)

    try:
        uri = "https://" + server + \
            "/irisservices/api/v1/public/protectionJobs/run/" + str(self['id'])
        headers = {"Accept": "application/json",
                   "Authorization": "Bearer " + token,
                   "user-agent": "cohesity-ansible/v0.0.1"}
        source_ids = payload.get('sourceIds', [])
        payload = dict()
        payload['runNowParameters'] = [{'sourceId':source_id} for source_id in source_ids]
        payload['name'] = self['name']
        payload['environment'] = self['environment']

        payload['runType'] = "k" + self['runType']

        data = json.dumps(payload)
        response = open_url(url=uri, data=data, headers=headers,
                            validate_certs=validate_certs, timeout=REQUEST_TIMEOUT)
        # => There is no data output so if we get a 204 then we are
        # => happy.
        if not response.getcode() == 204:
            raise ProtectionException(
                msg="Something went wrong with the attempt to start protection job %s" %
                self['id'])

        # => This dictionary will allow us to return a standardized output
        # => for all Protection Job.
        output = dict(
            id=self['id']
        )

        # => It can take a few moments for the job to actually stop.  In this case,
        # => We will introduce a delay and check every (5) seconds for up to a minute
        # => to see if the job stopped.
        wait__for_job_state__transition(
            module, self, [self['id']], state='start')

        return output
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def update_job(module, job_details, update_source_ids=None):
    server = module.params.get('cluster')
    validate_certs = module.params.get('validate_certs')
    token = job_details['token']
    try:
        uri = "https://" + server + \
            "/irisservices/api/v1/public/protectionJobs/" + str(job_details['id'])
        headers = {"Accept": "application/json",
                   "Authorization": "Bearer " + token,
                   "user-agent": "cohesity-ansible/v0.0.1"}
        payload = job_details.copy()
        del payload['token']
        if module.params.get('environment') == 'PhysicalFiles' and module.params.get('delete_sources') == False:
            if 'sourceSpecialParameters' in payload:
                updated_source_params = []
                for parameter in payload['sourceSpecialParameters']:
                    if parameter['sourceId'] not in update_source_ids:
                        updated_source_params.append(parameter)
                payload['sourceSpecialParameters'] = updated_source_params
            if module.params.get('state') == 'present':
                payload['sourceSpecialParameters'].extend(create_paths_parameter(module, update_source_ids))
        data = json.dumps(payload)
        response = open_url(
            url=uri,
            data=data,
            headers=headers,
            validate_certs=validate_certs,
            method="PUT", timeout=REQUEST_TIMEOUT)
        if not response.getcode() == 200:
            raise ProtectionException(
                msg="Something went wrong with the attempt to get protection job %s" %
                job_details['id'])

        response = json.loads(response.read())
        output = dict(
            id=response['id'],
            name=response['name'],
            environment=response['environment'].lstrip('k'),
        )
        return output
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def get_prot_job_details(self, module):
    server = module.params.get('cluster')
    validate_certs = module.params.get('validate_certs')
    token = self['token']
    try:
        uri = "https://" + server + \
            "/irisservices/api/v1/public/protectionJobs/" + str(self['id'])

        headers = {"Accept": "application/json",
                   "Authorization": "Bearer " + token,
                   "user-agent": "cohesity-ansible/v0.0.1"}
        response = open_url(url=uri, headers=headers,
                            validate_certs=validate_certs, timeout=REQUEST_TIMEOUT)
        if not response.getcode() == 200:
            raise ProtectionException(
                msg="Something went wrong with the attempt to get protection job %s" %
                self['id'])

        output = json.loads(response.read())
        return output
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def stop_job(module, self):
    server = module.params.get('cluster')
    validate_certs = module.params.get('validate_certs')
    token = self['token']

    payload = self.copy()
    payload['active_only'] = True
    payload['is_deleted'] = False
    currently_active = get__protection_run__all__by_id(module, payload)
    if not currently_active:
        results = dict(
            changed=False,
            msg="The Protection Job for this host is not currently running",
            name=module.params.get('name')
        )
        module.exit_json(**results)
    if not module.params.get('cancel_active') and currently_active:
        module.fail_json(
            changed=False,
            msg="The Protection Job for this host is active and cannot be stopped")
    try:
        uri = "https://" + server + \
            "/irisservices/api/v1/public/protectionRuns/cancel/" + \
            str(self['id'])
        headers = {"Accept": "application/json",
                   "Authorization": "Bearer " + token,
                   "user-agent": "cohesity-ansible/v0.0.1"}
        payload = self.copy()

        # => Remove the Authorization Token from the Payload
        payload.pop('token', None)

        output = dict(
            id=self['id'],
            cancel_active=module.params.get('cancel_active'),
            jobRunIds=list()
        )
        for backup_run in currently_active:
            payload['jobRunId'] = backup_run['backupRun']['jobRunId']

            data = json.dumps(payload)
            response = open_url(url=uri, data=data, headers=headers,
                                validate_certs=validate_certs, timeout=REQUEST_TIMEOUT)

            # => There is no data output so if we get a 204 then we are
            # => happy.
            if not response.getcode() == 204:
                raise ProtectionException(
                    msg="Something went wrong with the attempt to cancel protection job %s" % str(
                        self['id']))

            # => This dictionary will allow us to return a standardized output
            # => for all Protection Job.
            output['jobRunIds'].append(payload['jobRunId'])

        # => It can take a few moments for the job to actually stop.  In this case,
        # => We will introduce a delay and check every (5) seconds for up to a minute
        # => to see if the job stopped.
        wait__for_job_state__transition(
            module, self, output['jobRunIds'], state='stop')

        return output
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def unregister_job(module, self):
    server = module.params.get('cluster')
    validate_certs = module.params.get('validate_certs')
    token = self['token']
    try:
        uri = "https://" + server + \
            "/irisservices/api/v1/public/protectionJobs/" + str(self['id'])
        headers = {"Accept": "application/json",
                   "Authorization": "Bearer " + token,
                   "user-agent": "cohesity-ansible/v0.0.1"}

        payload = dict(
            deleteSnapshots=self['deleteSnapshots']
        )
        data = json.dumps(payload)

        response = open_url(
            url=uri,
            method='DELETE',
            data=data,
            headers=headers,
            validate_certs=validate_certs, timeout=REQUEST_TIMEOUT)

        return response
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def update_vmware_job(module, job_meta_data, job_details):
    if len(module.params.get('exclude')) != 0 or len(module.params.get('include')) != 0:
        if len(module.params.get('exclude')) != 0:
            vms = module.params.get('exclude')
            exclude_vm_ids = get_vmware_ids(module, job_meta_data, job_details, vms)
            job_meta_data['excludeSourceIds'] = exclude_vm_ids
        if len(module.params.get('include')) != 0:
            vms = module.params.get('include')
            include_vm_ids = get_vmware_ids(module, job_meta_data, job_details, vms)
            append_to_existing = module.params.get('append_to_existing')
            # If append_to_existing is set to true, then job sources are replaced with
            # latest include vms, if append_to_existing is set to false latest include
            # vms are added to existing vms.
            if append_to_existing == True:
                existing_source_ids = job_meta_data["sourceIds"]
                include_vm_ids.extend([
                    source_id for source_id in existing_source_ids if source_id not in include_vm_ids])
            job_meta_data['sourceIds'] = include_vm_ids
        job_meta_data['token'] = job_details['token']
        if len(module.params.get('include_tags')) != 0:
            tag_list = list()
            for tags in module.params.get('include_tags'):
                tag_ids = _get_tag_ids(module, tags, job_meta_data['parentSourceId'])
                tag_list.append(tag_ids)
            job_meta_data['vmTagIds'] = tag_list
        response = update_job(module, job_meta_data, "")
        results = dict(
            changed=True,
            msg="Successfully updated the protection job",
            **response)
        module.exit_json(**results)
    else:
        module.exit_json(
            msg="The protection job already exists",
            id=job_meta_data['id'],
            name=module.params.get('name'),
            changed=False
        )


def delete_sources(module, job_meta_data, job_details):
    missing_sources = []
    job_details['environment'] = 'Physical'
    try:
        for source in module.params.get('protection_sources'):
            job_details['endpoint'] = source['endpoint']
            source_id = get__prot_source_id__by_endpoint(
                module, job_details)
            if source_id in job_meta_data['sourceIds']:
                job_meta_data['sourceIds'].remove(source_id)
            else:
                missing_sources.append(source['endpoint'])
            if module.params.get('environment') == 'PhysicalFiles':
                for source in job_meta_data['sourceSpecialParameters']:
                    if source['sourceId'] == source_id:
                        index = job_meta_data['sourceSpecialParameters'].index(source)
                        del job_meta_data['sourceSpecialParameters'][index]
        if len(job_meta_data['sourceIds']) == 0:
            module.fail_json(
                msg="Cannot remove all the sources from a protection job.",
                id=job_meta_data['id'],
                changed=False,
                name=module.params.get('name'))
        if missing_sources:
            # If any source provided is not available in the job, sources are not updated.
            module.fail_json(
                msg="Removing sources from protection job failed. Following list of sources"
                    " are not available in the job: %s" % ", ".join(missing_sources),
                id=job_meta_data['id'],
                changed=False,
                name=module.params.get('name'))
        job_meta_data['token'] = job_details['token']
        response = update_job(module, job_meta_data)
        module.exit_json(
                changed=True,
                msg="Successfully removed sources from the protection job",
                **response)
    except Exception as err:
        module.fail_json(
                changed=False,
                msg="Error while removing sources from the protection job")


def update_job_util(module, job_details, job_exists):
    if len(module.params.get('protection_sources')
           ) == 1 and not module.params.get('protection_sources')[0]:
        module.fail_json(
            msg="Missing protection sources to add to the existing protection job",
            id=job_exists,
            name=module.params.get('name'))

    job_details['id'] = job_exists
    job_details['sourceIds'] = list()
    if job_details['environment'] == "PhysicalFiles":
        job_details['environment'] = "Physical"
    prot_source = dict(
        environment=job_details['environment'],
        token=job_details['token']
    )
    i = 0
    for source in module.params.get('protection_sources'):
        prot_source['endpoint'] = source['endpoint']
        source_id = get__prot_source_id__by_endpoint(
            module, prot_source)
        if source_id:
            job_details['sourceIds'].append(source_id)
            module.params.get('protection_sources')[i]['endpoint'] = source_id
        else:
            module.params.get('protection_sources')[i]['endpoint'] = None
        i += 1
    job_details['parentSourceId'] = get__prot_source_root_id__by_environment(
        module, job_details)
    job_details['environment'] = module.params.get('environment')
    existing_job_details = get_prot_job_details(job_details, module)
    already_exist_in_job = set(
        job_details['sourceIds']).issubset(
        existing_job_details['sourceIds'])

    update_sources = []
    is_indexing_updated = False
    indexing_policy = existing_job_details["indexingPolicy"]
    indexing = module.params.get('indexing', {})
    if module.params.get('disable_indexing') == False:
        if (set(indexing.get('allowed_prefix', [])) != set(indexing_policy.get('allowPrefixes', []))) or (set(indexing.get('denied_prefix', [])) != set(indexing_policy.get('denyPrefixes', []))):
            update_indexing(module, existing_job_details)
            is_indexing_updated = True
    if indexing_policy["disableIndexing"] != module.params.get('disable_indexing'):
        update_indexing(module, existing_job_details)
        is_indexing_updated = True
    if job_details['environment'] == 'PhysicalFiles':
        existing_file_path = defaultdict(dict)
        # Fetch existing include exclude path details.
        for each_source in existing_job_details['sourceSpecialParameters']:
            source_id = each_source['sourceId']
            existing_file_path[source_id] = {_params['backupFilePath']:_params.get('excludedFilePaths', []) for _params in each_source['physicalSpecialParameters']['filePaths']}
        for source in module.params.get('protection_sources'):
            source_id = source['endpoint']
            # Check the source is already available in the job.
            if source_id not in list(existing_file_path.keys()):
                continue
            paths = source.get('paths', [])
            if not paths:
                update_sources.append(source_id)
                continue
            for path in paths:
                include_path = path.get('includeFilePath', '')
                exclude_path = path.get('excludeFilePaths', [])

                # Check whether the include path is already available.
                if include_path not in list(existing_file_path[source_id].keys()):
                    update_sources.append(source_id)
                    break

                # Check if existing excluded path matches with new exclude path.
                if sorted(exclude_path) != sorted(existing_file_path[source_id][include_path]):
                    update_sources.append(source_id)
                    break
    if update_sources:
        already_exist_in_job = False
    if not is_indexing_updated and already_exist_in_job and len(job_details['sourceIds']) != 0:
        results = dict(
            changed=False,
            msg="The protection sources are already being protected",
            id=job_exists,
            name=module.params.get('name')
        )
    elif is_indexing_updated or (not already_exist_in_job and len(job_details['sourceIds']) != 0):
        indexing_msg = ""
        new_sources = list(set(job_details['sourceIds']).difference(existing_job_details['sourceIds']))
        if update_sources:
            # Add sources with updated paths to new sources.
            new_sources.extend(update_sources)
            [existing_job_details['sourceIds'].remove(_id) for _id in new_sources if _id in existing_job_details['sourceIds']]
        existing_job_details['sourceIds'].extend(new_sources)
        existing_job_details['token'] = job_details['token']
        if is_indexing_updated:
            indexing_msg = "indexing policies, "
        response = update_job(module, existing_job_details, new_sources)
        if job_details['environment'] == 'PhysicalFiles':
            msg = "Successfully updated " + indexing_msg + "sources and filepaths to existing protection job"
        else:
            msg = "Successfully updated " + indexing_msg + "sources to existing protection job"
        results = dict(
            changed=True,
            msg=msg,
            **response)
    else:
        module.fail_json(
            msg="Sources don't exist on the cluster",
            id=job_exists,
            name=module.params.get('name')
        )
    module.exit_json(**results)


def main():
    # => Load the default arguments including those specific to the Cohesity Protection Jobs.
    argument_spec = cohesity_common_argument_spec()
    argument_spec.update(
        dict(
            state=dict(choices=['present', 'absent',
                                'started', 'stopped'], default='present'),
            name=dict(type='str', required=True, aliases=['job_name']),
            description=dict(type='str', default=''),
            # => Currently, the only supported environments types are list in the choices
            # => For future enhancements, the below list should be consulted.
            # => 'SQL', 'View', 'Puppeteer', 'Pure', 'Netapp', 'HyperV', 'Acropolis', 'Azure'
            environment=dict(
                choices=['VMware', 'PhysicalFiles', 'Physical', 'GenericNas', 'View'],
                default='PhysicalFiles'
            ),
            view_name=dict(type='str', required=False),
            protection_sources=dict(type='list', aliases=['sources'], default=''),
            protection_policy=dict(type='str', aliases=['policy'], default='Bronze'),
            storage_domain=dict(type='str', default='DefaultStorageDomain'),
            delete_sources=dict(type='bool', default=False),
            time_zone=dict(type='str', default='America/Los_Angeles'),
            start_time=dict(type='str', default=''),
            delete_backups=dict(type='bool', default=False),
            ondemand_run_type=dict(
                choices=['Regular', 'Full', 'Log', 'System'], default='Regular'),
            cancel_active=dict(type='bool', default=False),
            validate_certs=dict(type='bool', default=False),
            append_to_existing=dict(type='bool', default=False),
            exclude=dict(type=list, default=''),
            include=dict(type=list, default=''),
            exclude_tags=dict(type=list, default=''),
            include_tags=dict(type=list, default=''),
            disable_indexing=dict(type=bool, default=False),
            indexing=dict(type=dict, default={})
        )
    )

    # => Create a new module object
    module = AnsibleModule(argument_spec=argument_spec,
                           supports_check_mode=True)
    results = dict(
        changed=False,
        msg="Attempting to manage Protection Source",
        state=module.params.get('state')
    )

    job_details = dict(
        token=get__cohesity_auth__token(module),
        name=module.params.get('name'),
        description=module.params.get('description'),
        environment=module.params.get('environment'),
        sourceIds=module.params.get('protection_sources'),
        policyId=module.params.get('protection_policy'),
        viewBoxId=module.params.get('storage_domain'),
        timezone=module.params.get('time_zone')
    )

    job_exists, job_meta_data = check__protection_job__exists(module, job_details)

    if module.check_mode:
        check_mode_results = dict(
            changed=False,
            msg="Check Mode: Cohesity Protection Job is not currently registered",
            id="")
        if module.params.get('state') == "present":
            if job_exists:
                check_mode_results[
                    'msg'] = "Check Mode: Cohesity Protection Job is currently registered.  No changes"
            else:
                check_mode_results[
                    'msg'] = "Check Mode: Cohesity Protection Job is not currently registered.  This action would register the Cohesity Protection Job."
                check_mode_results['id'] = job_exists
        else:
            if job_exists:
                check_mode_results[
                    'msg'] = "Check Mode: Cohesity Protection Job is currently registered.  This action would unregister the Cohesity Protection Job."
                check_mode_results['id'] = job_exists
            else:
                check_mode_results[
                    'msg'] = "Check Mode: Cohesity Protection Job is not currently registered.  No changes."
        module.exit_json(**check_mode_results)

    elif module.params.get('state') == "present":

        results['source_vars'] = job_details
        if job_exists:
            if module.params.get('delete_sources') == True:
                delete_sources(module, job_meta_data, job_details)
            if module.params.get('environment') == "VMware":
                update_vmware_job(module, job_meta_data, job_details)
            if module.params.get('environment') in ("PhysicalFiles", "Physical", "GenericNas"):
                update_job_util(module, job_details, job_exists)
            else:
                module.exit_json(
                    msg="The protection job already exists",
                    id=job_exists,
                    name=module.params.get('name'),
                    changed=False
                )

        else:
            check__mandatory__params(module)
            if job_details['environment'] == 'View':
                job_details['viewName'] = module.params.get('view_name')
                job_details['viewBoxId'] = get_view_storage_domain_id(module, job_details)
                del job_details['sourceIds']
            else:
                job_details['sourceIds'] = list()
                if job_details['environment'] == "PhysicalFiles":
                    job_details['environment'] = "Physical"
                prot_source = dict(
                    environment=job_details['environment'],
                    token=job_details['token']
                )
                i = 0
                for source in module.params.get('protection_sources'):
                    prot_source['endpoint'] = source['endpoint']
                    source_id = get__prot_source_id__by_endpoint(
                        module, prot_source)
                    if source_id:
                        job_details['sourceIds'].append(source_id)
                        module.params.get('protection_sources')[i]['endpoint'] = source_id
                    else:
                        module.params.get('protection_sources')[i]['endpoint'] = None
                    i += 1

                job_details['parentSourceId'] = get__prot_source_root_id__by_environment(
                    module, job_details)
                job_details['viewBoxId'] = get__storage_domain_id__by_name(
                    module, job_details)
            job_details['environment'] = module.params.get('environment')
            job_details['policyId'] = get__prot_policy_id__by_name(
                module, job_details)
            if module.params.get('start_time'):
                start_time = module.params.get(
                    'start_time').replace(":", "")
                if not len(start_time) == 4:
                    # => There are only so many options here but if we get more characters
                    # => than four then we need to escape quickly.
                    module.fail_json(
                        msg="Invalid start_time selected (" +
                        module.params.get('start_time') +
                        ").  Please review and submit the correct Protection Job Starting time.")
                job_details['startTime'] = dict(
                    hour=int(start_time[0] + start_time[1]),
                    minute=int(start_time[2] + start_time[3])
                )

            response = register_job(module, job_details)

            results = dict(
                changed=True,
                msg="Registration of Cohesity Protection Job Complete",
                **response
            )

    elif module.params.get('state') == "absent":
        if job_exists:
            if len(module.params.get('protection_sources')
                   ) == 1 and not module.params.get('protection_sources')[0]:
                job_details['id'] = job_exists
                job_details['deleteSnapshots'] = module.params.get(
                    'delete_backups')

                response = unregister_job(module, job_details)

                results = dict(
                    changed=True,
                    msg="Unregistration of Cohesity Protection Job Complete",
                    id=job_exists,
                    name=module.params.get('name')
                )
            else:
                job_details['id'] = job_exists
                job_details['sourceIds'] = list()
                if job_details['environment'] == "PhysicalFiles":
                    job_details['environment'] = "Physical"
                prot_source = dict(
                    environment=job_details['environment'],
                    token=job_details['token']
                )
                for source in module.params.get('protection_sources'):
                    prot_source['endpoint'] = source['endpoint']
                    source_id = get__prot_source_id__by_endpoint(
                        module, prot_source)
                    if source_id:
                        job_details['sourceIds'].append(source_id)
                job_details['parentSourceId'] = get__prot_source_root_id__by_environment(
                    module, job_details)
                job_details['environment'] = module.params.get('environment')
                existing_job_details = get_prot_job_details(
                    job_details, module)
                sources_exiting_in_job = set(
                    job_details['sourceIds']).intersection(
                    existing_job_details['sourceIds'])
                if len(sources_exiting_in_job) != 0 and len(
                        sources_exiting_in_job) != len(existing_job_details['sourceIds']):
                    existing_job_details['sourceIds'] = list(
                        set(existing_job_details['sourceIds']).difference(job_details['sourceIds']))
                    existing_job_details['token'] = job_details['token']
                    response = update_job(module, existing_job_details, sources_exiting_in_job)
                    results = dict(
                        changed=True,
                        msg="Successfully removed the sources from existing protection job",
                        **response)
                elif len(sources_exiting_in_job) != 0 and len(sources_exiting_in_job) == len(existing_job_details['sourceIds']):
                    module.fail_json(
                        msg="Cannot remove all sources from protection job",
                        changed=False)
                else:
                    results = dict(
                        changed=False,
                        msg="The protection job doesn't have the sources",
                        id=job_exists,
                        name=module.params.get('name')
                    )
        else:
            results = dict(
                changed=False,
                msg="The Protection Job for this host is currently not registered",
                name=module.params.get('name'))

    elif module.params.get('state') == "started":
        if job_exists:
            job_details['id'] = job_exists
            job_details['sourceIds'] = []
            job_details['runType'] = module.params.get(
                'ondemand_run_type')

            prot_source = dict(
                    environment=job_details['environment'],
                    token=job_details['token']
            )
            if module.params.get('environment') == 'VMware':
                ids = []
                job_meta_data = {"parentSourceId": job_meta_data['parentSourceId']}
                if len(module.params.get('include')) != 0:
                    vms = module.params.get('include')
                    ids = get_vmware_ids(module, job_meta_data, job_details, vms)
                job_details['sourceIds'] = ids
            elif 'Physical' in module.params.get('environment'):
                prot_source['environment'] = 'Physical'
                for source in module.params.get('protection_sources'):
                    if source and type(source) == dict:
                        prot_source['endpoint'] = source['endpoint']
                        source_id = get__prot_source_id__by_endpoint(
                            module, prot_source)
                        if source_id:
                            job_details['sourceIds'].append(source_id)
            response = start_job(module, job_details)

            results = dict(
                changed=True,
                msg="The Protection Job for this host has been started",
                id=job_exists,
                name=module.params.get('name')
            )
        else:
            results = dict(
                changed=False,
                msg="The Protection Job for this host is currently not registered",
                name=module.params.get('name'))

    elif module.params.get('state') == "stopped":
        if job_exists:
            job_details['id'] = job_exists

            response = stop_job(module, job_details)

            results = dict(
                changed=True,
                msg="The Protection Job for this host has been stopped",
                id=job_exists,
                name=module.params.get('name')
            )
        else:
            results = dict(
                changed=False,
                msg="The Protection Job for this host is currently not registered",
                name=module.params.get('name'))
    else:
        # => This error should never happen based on the set assigned to the parameter.
        # => However, in case, we should raise an appropriate error.
        module.fail_json(msg="Invalid State selected: {0}".format(
            module.params.get('state')), changed=False)

    module.exit_json(**results)


if __name__ == '__main__':
    main()